{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "theAssemblyWorkshop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1IKglu6Sf4r"
      },
      "source": [
        "#FaceMask detection model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW7eMmb1Ssaj"
      },
      "source": [
        "**Build your CNN model using Keras to identify whether a person is wearing a faceMask or not**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FBX03tXTDJ4"
      },
      "source": [
        "###**1**.   **The Setup phase**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk2SJem1TCfv"
      },
      "source": [
        "#---------------------------The import statments-----------------------------------------\n",
        "\n",
        "import pandas as pd                               #reading, writing and manipulating the data (using tables)\n",
        "import numpy as np                                #Library for linear algebra and some probabiltity (raw data) \n",
        "import tensorflow as tf                           #library for numerical computation that makes machine learning faster and easier\n",
        "from tensorflow import keras                      #we may not add this since keras is already thier in tensorflow\n",
        "from tensorflow.keras.models import Sequential    #To create the sequential layer\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D,Dropout  #To create the model\n",
        "from tensorflow.keras.optimizers import Adam      #Adam optimizer\n",
        "from keras.preprocessing import image             #used for image classification\n",
        "from keras.preprocessing.image import ImageDataGenerator  #used to expand the training dataset in order to improve the performance and ability of the model to generalize\n",
        "import matplotlib.pyplot as plt                   #library to plot graphs\n",
        "from google.colab import files                    #To be able to upload files                          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih6T8eYyZOP3"
      },
      "source": [
        "Here I will upload the dataset file called `\"data\"` that has 2 subfolders `\"with\"` and `\"without`\" and unzip\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXYnJTh8XTMY"
      },
      "source": [
        "#upload file\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VrTw-gqOZAq"
      },
      "source": [
        "#unzipping the folder\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ET7hWGKfPB-"
      },
      "source": [
        "#delete the zip file as it is not needed anymore\n",
        "!rm data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkjRtDw0Hhu4"
      },
      "source": [
        "# setting the batch size and the epochs\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59vUXpFlYZK-"
      },
      "source": [
        "Splitting the images (80% training and 20% \n",
        "validation) and Data augmanting it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYggOThqYYN4"
      },
      "source": [
        "\n",
        "\n",
        "directory = 'data'\n",
        "\n",
        "train_datagen = ImageDataGenerator(validation_split=0.2,        # Splits the data into training (80%) and validation (20%)\n",
        "                                   rescale = 1./255,            # Multiple the colors by a number between 0-1 to process data faster\n",
        "                                   rotation_range=40,           #rotate the images\n",
        "                                   width_shift_range=0.2,     \n",
        "                                   height_shift_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')        #add new pixels when the image is rotated or shifted\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                directory,\n",
        "                                target_size = (70, 70),\n",
        "                                batch_size = batch_size,\n",
        "                                color_mode=\"rgb\",               # for coloured images\n",
        "                                class_mode = 'binary',\n",
        "                                seed=2020,                      # to make the result reproducible\n",
        "                                subset = 'training')            # Specify this is training set\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "                                directory,\n",
        "                                target_size = (70, 70),\n",
        "                                batch_size = batch_size,\n",
        "                                color_mode=\"rgb\",               # for coloured images\n",
        "                                class_mode = 'binary',\n",
        "                                subset = 'validation')            # Specify this is training set\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drYp_mO7ICUu"
      },
      "source": [
        "**Display a batch of the images used in the training and thier labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld4QAqg4IBi4"
      },
      "source": [
        "#generate a batch of images and labels from the training set\n",
        "imgs, labels = next(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3AUD1pXIXb_"
      },
      "source": [
        "#plotting function\n",
        "\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, batch_size, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxt3aeyNIYU9"
      },
      "source": [
        "#displaying the images and thier labels where as 0 with mask and 1 without mask\n",
        "plotImages(imgs);\n",
        "print(labels);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG0mM8yggu0e"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "###**2. Build and train the CNN**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZvVgvRokJeJ"
      },
      "source": [
        "Sequencial is a list of the layers of the model we want to create. Here it consists of\n",
        "\n",
        "*   Conv2D Layer\n",
        "> * **The filter** parameter means the number of this layer's output filters \n",
        "> *   **The kernal_size** parameter is commonly used 3*3\n",
        "> *   **The activation** parameter refers to the type of activation function\n",
        "> *   **The padding** parameter is enabled to zero-padding\n",
        "> *   **The input_shape** parameter has pixel high and pixel wide and have the 3 color channels: RGB\n",
        "\n",
        "*   MaxPool2D Layer\n",
        "> To pool and reduce the dimensionlaity of the data\n",
        "*   Flatten Layer\n",
        "> * flatten is used to flatten the input to a 1D vector then passed to dense\n",
        "\n",
        "*   Dense Layer (The output layer)\n",
        "> * **The units** parameter means that it has 2 nodes one for with and one for without because we want a binary output \n",
        "> *   **The activation** parameter we use the softmax activation function on our output so that the output for each sample is a probability distribution over the outputs of with and without mask\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSFD3JDdN9Fr"
      },
      "source": [
        "#create the model layers\n",
        "\n",
        "model = Sequential([\n",
        "                    Conv2D(filters=32, kernel_size=(3,3),activation='relu',padding='same',input_shape=(70,70,3)),\n",
        "                    MaxPool2D(pool_size=(2,2), strides=2),\n",
        "                    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding= 'same'),\n",
        "                    MaxPool2D(pool_size=(2,2), strides =2),\n",
        "                    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding= 'same'),\n",
        "                    MaxPool2D(pool_size=(2,2), strides =2),\n",
        "                    Flatten(),\n",
        "                    Dense(units=64, activation= 'relu'),\n",
        "                    #means the output is 0,1 (the labels) and the P(c=0) +P(c=1) = 1 \n",
        "                    Dense(units=1, activation='sigmoid'), \n",
        "\n",
        "])\n",
        "\n",
        "#check out the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTdz4MtVTy7i"
      },
      "source": [
        "Compile the model using the **Adam** optimizer with **learning rate** of `0.0001`, a **loss** of `binary_crossentropy`, and we'll look at `accuracy` as our performance **metric**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSITIIHuTyBQ"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERuAVVRaUvGk"
      },
      "source": [
        "We use the `train_generator` because we are now only training the data. The \n",
        "validation data is the `validation_generator` \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aC83morUtyp"
      },
      "source": [
        "#Training the model\n",
        "history = model.fit(train_generator ,epochs = epochs,validation_data= validation_generator) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsUnQyFnYDkS"
      },
      "source": [
        "\n",
        "\n",
        "### **3. Plotting the loss and accuracy of training vs validation**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627OK11rYiYO"
      },
      "source": [
        "#Plotting the loss of validation and training \n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochstoplot = range(1,epochs+1)\n",
        "plt.plot(epochstoplot, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochstoplot, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSSt2DJZY5qK"
      },
      "source": [
        "#Plotting the accuracy of validation and training \n",
        "accur_train = history.history['accuracy']\n",
        "accur_val = history.history['val_accuracy']\n",
        "plt.plot(epochstoplot, accur_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochstoplot, accur_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AugzFppxIbiY"
      },
      "source": [
        "### **4. Testing the CNN model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U-E1qlBcDif"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "TGREEN =  '\\033[1;37;42m'\n",
        "TRED =    '\\033[1;37;41m'\n",
        "for i in range (1,17):\n",
        "  img_directory = str(i) + '.jpg'\n",
        "  img_pred = image.load_img(img_directory, target_size = (70, 70))\n",
        "  img_pred = image.img_to_array(img_pred)\n",
        "  img_pred = np.expand_dims(img_pred, axis = 0)\n",
        "\n",
        "  prediction = model.predict(img_pred)\n",
        "  display(Image(img_directory,width= 150, height=150))\n",
        "  print(\"\\n\")\n",
        "  if(int(prediction[0][0]) == 0):\n",
        "    print(TGREEN + \"The person is wearing a mask. \\n\")\n",
        "  else:\n",
        "    print(TRED + \"The person is not wearing a mask.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}